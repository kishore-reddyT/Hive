{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.hql\n",
    "\n",
    "USE stackoverflow_;\n",
    "\n",
    "\n",
    "WITH questions AS (\n",
    "    SELECT year, tags_expl, COUNT(*) AS cnt\n",
    "    FROM posts\n",
    "    LATERAL VIEW explode(tags) tagsTable AS tags_expl\n",
    "    WHERE post_type_id = 1 AND year IN (2009, 2016)\n",
    "    GROUP BY year, tags_expl\n",
    ")\n",
    "SELECT concat_ws(\"\\t\", tags_expl, string(rank_2016), string(rank_2009), string(cnt_2016), string(cnt_2009))\n",
    "FROM (\n",
    "    SELECT\n",
    "        t_2016.tags_expl AS tags_expl\n",
    "        ,t_2016.rank AS rank_2016\n",
    "        ,t_2009.rank AS rank_2009\n",
    "        ,t_2016.cnt AS cnt_2016\n",
    "        ,t_2009.cnt AS cnt_2009\n",
    "    FROM (\n",
    "        SELECT tags_expl, cnt, RANK() OVER (ORDER BY cnt DESC) rank\n",
    "        FROM questions\n",
    "        WHERE year = 2016\n",
    "        LIMIT 10\n",
    "    ) t_2016\n",
    "    LEFT OUTER JOIN (\n",
    "        SELECT tags_expl, cnt, RANK() OVER (ORDER BY cnt DESC) rank\n",
    "        FROM questions\n",
    "        WHERE year = 2009\n",
    "    ) t_2009\n",
    "    ON t_2016.tags_expl = t_2009.tags_expl\n",
    "    ORDER BY rank_2016\n",
    ") t_top;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 1.155 seconds\n",
      "Query ID = jovyan_20180527103939_0803f688-d551-4d89-82ec-cc4c6ebdd14d\n",
      "Total jobs = 8\n",
      "Launching Job 1 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1527414825805_0012, Tracking URL = http://c9bfde1d3c8a:8088/proxy/application_1527414825805_0012/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1527414825805_0012\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2018-05-27 10:40:04,626 Stage-1 map = 0%,  reduce = 0%\n",
      "2018-05-27 10:40:14,471 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 7.5 sec\n",
      "2018-05-27 10:40:23,242 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 12.6 sec\n",
      "MapReduce Total cumulative CPU time: 12 seconds 600 msec\n",
      "Ended Job = job_1527414825805_0012\n",
      "Launching Job 2 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1527414825805_0013, Tracking URL = http://c9bfde1d3c8a:8088/proxy/application_1527414825805_0013/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1527414825805_0013\n",
      "Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 1\n",
      "2018-05-27 10:40:41,129 Stage-6 map = 0%,  reduce = 0%\n",
      "2018-05-27 10:40:52,489 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 6.21 sec\n",
      "2018-05-27 10:41:03,558 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 10.64 sec\n",
      "MapReduce Total cumulative CPU time: 10 seconds 640 msec\n",
      "Ended Job = job_1527414825805_0013\n",
      "Launching Job 3 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1527414825805_0014, Tracking URL = http://c9bfde1d3c8a:8088/proxy/application_1527414825805_0014/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1527414825805_0014\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2018-05-27 10:41:21,054 Stage-2 map = 0%,  reduce = 0%\n",
      "2018-05-27 10:41:29,737 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 4.98 sec\n",
      "2018-05-27 10:41:41,016 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 12.15 sec\n",
      "MapReduce Total cumulative CPU time: 12 seconds 150 msec\n",
      "Ended Job = job_1527414825805_0014\n",
      "Launching Job 4 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1527414825805_0015, Tracking URL = http://c9bfde1d3c8a:8088/proxy/application_1527414825805_0015/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1527414825805_0015\n",
      "Hadoop job information for Stage-7: number of mappers: 1; number of reducers: 1\n",
      "2018-05-27 10:41:59,725 Stage-7 map = 0%,  reduce = 0%\n",
      "2018-05-27 10:42:08,367 Stage-7 map = 100%,  reduce = 0%, Cumulative CPU 4.12 sec\n",
      "2018-05-27 10:42:16,928 Stage-7 map = 100%,  reduce = 100%, Cumulative CPU 9.26 sec\n",
      "MapReduce Total cumulative CPU time: 9 seconds 260 msec\n",
      "Ended Job = job_1527414825805_0015\n",
      "Launching Job 5 out of 8\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1527414825805_0016, Tracking URL = http://c9bfde1d3c8a:8088/proxy/application_1527414825805_0016/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1527414825805_0016\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2018-05-27 10:42:35,048 Stage-3 map = 0%,  reduce = 0%\n",
      "2018-05-27 10:42:42,511 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.44 sec\n",
      "2018-05-27 10:42:52,100 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 5.55 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 550 msec\n",
      "Ended Job = job_1527414825805_0016\n",
      "Stage-10 is selected by condition resolver.\n",
      "Stage-4 is filtered out by condition resolver.\n",
      "Execution log at: /tmp/jovyan/jovyan_20180527103939_0803f688-d551-4d89-82ec-cc4c6ebdd14d.log\n",
      "2018-05-27 10:42:58\tStarting to launch local task to process map join;\tmaximum memory = 477626368\n",
      "2018-05-27 10:43:00\tDump the side-table for tag: 1 with group count: 2369 into file: file:/tmp/jovyan/8fc92d08-a876-40e9-bebd-0b414e8fc53a/hive_2018-05-27_10-39-46_265_4265102461768023293-1/-local-10009/HashTable-Stage-8/MapJoin-mapfile01--.hashtable\n",
      "2018-05-27 10:43:00\tUploaded 1 File to: file:/tmp/jovyan/8fc92d08-a876-40e9-bebd-0b414e8fc53a/hive_2018-05-27_10-39-46_265_4265102461768023293-1/-local-10009/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (76823 bytes)\n",
      "2018-05-27 10:43:00\tEnd of local task; Time Taken: 1.693 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 7 out of 8\n",
      "Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "Starting Job = job_1527414825805_0017, Tracking URL = http://c9bfde1d3c8a:8088/proxy/application_1527414825805_0017/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1527414825805_0017\n",
      "Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 0\n",
      "2018-05-27 10:43:13,649 Stage-8 map = 0%,  reduce = 0%\n",
      "2018-05-27 10:43:22,219 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 2.91 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 910 msec\n",
      "Ended Job = job_1527414825805_0017\n",
      "Launching Job 8 out of 8\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1527414825805_0018, Tracking URL = http://c9bfde1d3c8a:8088/proxy/application_1527414825805_0018/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1527414825805_0018\n",
      "Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1\n",
      "2018-05-27 10:43:38,989 Stage-5 map = 0%,  reduce = 0%\n",
      "2018-05-27 10:43:47,587 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 3.18 sec\n",
      "2018-05-27 10:43:56,165 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 8.62 sec\n",
      "MapReduce Total cumulative CPU time: 8 seconds 620 msec\n",
      "Ended Job = job_1527414825805_0018\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 12.6 sec   HDFS Read: 835508 HDFS Write: 283234 SUCCESS\n",
      "Stage-Stage-6: Map: 1  Reduce: 1   Cumulative CPU: 10.64 sec   HDFS Read: 145610 HDFS Write: 67863 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 12.15 sec   HDFS Read: 289183 HDFS Write: 364 SUCCESS\n",
      "Stage-Stage-7: Map: 1  Reduce: 1   Cumulative CPU: 9.26 sec   HDFS Read: 73690 HDFS Write: 74637 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 5.55 sec   HDFS Read: 4450 HDFS Write: 364 SUCCESS\n",
      "Stage-Stage-8: Map: 1   Cumulative CPU: 2.91 sec   HDFS Read: 4863 HDFS Write: 391 SUCCESS\n",
      "Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 8.62 sec   HDFS Read: 5613 HDFS Write: 188 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 1 minutes 1 seconds 730 msec\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript\t1\t5\t2771\t192\r\n",
      "java\t2\t2\t2033\t243\r\n",
      "android\t3\t52\t1809\t25\r\n",
      "php\t4\t3\t1673\t215\r\n",
      "python\t5\t11\t1585\t108\r\n",
      "c#\t6\t1\t1519\t423\r\n",
      "html\t7\t14\t1212\t84\r\n",
      "jquery\t8\t8\t1167\t141\r\n",
      "ios\t9\t186\t914\t7\r\n",
      "css\t10\t20\t801\t59\r\n",
      "Time taken: 252.085 seconds, Fetched: 10 row(s)\r\n"
     ]
    }
   ],
   "source": [
    "! hive -f query.hql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
